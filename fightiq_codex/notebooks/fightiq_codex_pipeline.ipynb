{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fe83d38",
   "metadata": {},
   "source": [
    "\n",
    "# FightIQ Codex: End-to-End UFC Fight Prediction Pipeline\n",
    "\n",
    "This notebook documents the FightIQ Codex project's leak-safe data pipeline, training workflow, and prediction tooling so it can be shared easily on Kaggle or any hosted notebook platform.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97125b9c",
   "metadata": {},
   "source": [
    "\n",
    "## Project Overview\n",
    "\n",
    "- **Leak-safe feature store** built from UFC Stats historical data with strict point-in-time (PTI) joins.\n",
    "- **Training scripts** for winner stacking ensemble (LightGBM/XGBoost + parity meta), multi-task method/round models, and calibrated betting helpers.\n",
    "- **Upcoming ingestion** that pulls odds via TheOddsAPI, engineers full pre-fight features, and produces calibrated predictions.\n",
    "- **Reusable command-line tooling** so the entire workflow can be orchestrated or cherry-picked inside a notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22efc9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "\n",
    "PROJECT_ROOT = Path('..').resolve().parent\n",
    "PROJECT_ROOT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fc388a",
   "metadata": {},
   "source": [
    "\n",
    "## Repository Layout\n",
    "\n",
    "Key directories you'll interact with:\n",
    "\n",
    "- data/: raw/silver/gold parquet layers generated from the ingestion pipeline.\n",
    "- \u0007rtifacts/: trained model bundles (LightGBM/XGBoost, calibrators, metadata).\n",
    "- scripts/: CLI entry points for ingestion, feature building, training, evaluation, and prediction.\n",
    "- \f",
    "ightiq_codex/data/: upcoming feature matrices used for inference notebooks or deployments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497613b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for path in [\n",
    "    PROJECT_ROOT / 'data',\n",
    "    PROJECT_ROOT / 'artifacts',\n",
    "    PROJECT_ROOT / 'fightiq_codex' / 'data',\n",
    "    PROJECT_ROOT / 'scripts'\n",
    "]:\n",
    "    print(f'? {path}')\n",
    "    for item in sorted(path.iterdir()):\n",
    "        if item.is_dir():\n",
    "            print(f'  [dir] {item.name}')\n",
    "        else:\n",
    "            size_mb = item.stat().st_size / 1e6\n",
    "            print(f'  {item.name} ({size_mb:.2f} MB)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8a671d",
   "metadata": {},
   "source": [
    "\n",
    "## Historical Feature Snapshot\n",
    "\n",
    "The gold layer contains leak-safe rolling statistics, matchup deltas, odds features, and rankings deltas for every historical fight.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69678bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gold_path = PROJECT_ROOT / 'data' / 'gold_features.parquet'\n",
    "gold_df = pd.read_parquet(gold_path)\n",
    "print(gold_df.shape)\n",
    "gold_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edff399",
   "metadata": {},
   "source": [
    "\n",
    "## Upcoming Feature Matrix\n",
    "\n",
    "Upcoming fights are ingested via scripts/ingest_upcoming_from_odds_api.py and enriched with the same feature engineering logic using scripts/build_upcoming_features.py.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e94530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "upcoming_path = PROJECT_ROOT / 'fightiq_codex' / 'data' / 'upcoming_features.parquet'\n",
    "upcoming_df = pd.read_parquet(upcoming_path)\n",
    "print(upcoming_df[['fight_url','event_date','f_1_name','f_2_name']].head())\n",
    "print('Feature columns:', len(upcoming_df.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77489ce",
   "metadata": {},
   "source": [
    "\n",
    "### Optional: Rebuild Upcoming Features\n",
    "\n",
    "Set RUN_INGEST to True if you want to pull fresh odds (requires THEODDS_API_KEY) and regenerate the upcoming feature matrix inside the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8e910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RUN_INGEST = False  # flip to True to re-run ingestion/feature build\n",
    "if RUN_INGEST:\n",
    "    import os\n",
    "    assert os.getenv('THEODDS_API_KEY'), 'Set THEODDS_API_KEY before running ingestion'\n",
    "    def run(cmd):\n",
    "        print('RUN:', ' '.join(cmd))\n",
    "        result = subprocess.run(cmd, cwd=str(PROJECT_ROOT), capture_output=True, text=True)\n",
    "        print(result.stdout)\n",
    "        if result.returncode != 0:\n",
    "            print(result.stderr)\n",
    "            raise RuntimeError(f'Command failed: {cmd}')\n",
    "    run(['python', 'scripts/ingest_upcoming_from_odds_api.py', '--regions', 'us', '--markets', 'h2h'])\n",
    "    run(['python', 'scripts/build_upcoming_features.py'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcccef4f",
   "metadata": {},
   "source": [
    "\n",
    "## Training & Evaluation Entrypoints\n",
    "\n",
    "Each training component can be executed directly from the notebook for reproducible experiments. Heavy jobs are disabled by default; enable the corresponding flags when running on your own hardware or Kaggle session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81c332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RUN_TRAINING = False  # toggle to True to retrain models\n",
    "if RUN_TRAINING:\n",
    "    def run(cmd):\n",
    "        print('RUN:', ' '.join(cmd))\n",
    "        result = subprocess.run(cmd, cwd=str(PROJECT_ROOT), capture_output=True, text=True)\n",
    "        print(result.stdout)\n",
    "        if result.returncode != 0:\n",
    "            print(result.stderr)\n",
    "            raise RuntimeError(f'Command failed: {cmd}')\n",
    "    run(['python', 'scripts/train_winner_enhanced.py', '--min-val-acc', '0.71', '--min-test-acc', '0.62'])\n",
    "    run(['python', 'scripts/train_multitask.py'])\n",
    "else:\n",
    "    print('Training skipped. Set RUN_TRAINING=True to retrain the models.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c9300d",
   "metadata": {},
   "source": [
    "\n",
    "## Generate Upcoming Predictions\n",
    "\n",
    "The prediction script loads the latest artifacts, blends parity + tuned models, and emits risk-controlled bets with calibrated method/round probabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b02d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions_path = None\n",
    "if RUN_INGEST or RUN_TRAINING:\n",
    "    result = subprocess.run(['python', 'scripts/predict_upcoming.py'], cwd=str(PROJECT_ROOT), capture_output=True, text=True)\n",
    "    print(result.stdout)\n",
    "    if result.returncode != 0:\n",
    "        print(result.stderr)\n",
    "        raise RuntimeError('Prediction failed')\n",
    "    for line in result.stdout.splitlines():\n",
    "        if 'Wrote predictions:' in line:\n",
    "            predictions_path = line.split(':', 1)[1].strip()\n",
    "else:\n",
    "    predictions_dir = PROJECT_ROOT / 'fightiq_codex' / 'outputs'\n",
    "    csv_files = sorted(predictions_dir.glob('upcoming_predictions_*.csv'))\n",
    "    if csv_files:\n",
    "        predictions_path = csv_files[-1]\n",
    "\n",
    "predictions_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0c89cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if predictions_path:\n",
    "    preds_df = pd.read_csv(predictions_path)\n",
    "    display(preds_df[['fight_url','f_1_name','f_2_name','predicted_winner','pred_win_prob_f1','kelly_frac_f1']].head())\n",
    "else:\n",
    "    print('No predictions available yet. Run the prediction cell above.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7de9df",
   "metadata": {},
   "source": [
    "\n",
    "## Next Steps\n",
    "\n",
    "- Upload this notebook and the data/ + \u0007rtifacts/ directories as Kaggle datasets to reproduce results online.\n",
    "- Customize the orchestration cell to run the full weekly pipeline (ingest ? validate ? train ? predict).\n",
    "- Extend with visualization cells (calibration curves, ROI trends) for richer storytelling in the notebook environment.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
